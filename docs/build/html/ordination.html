<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Ordination &mdash; ecopy 0.0.5 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.0.5',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="ecopy 0.0.5 documentation" href="index.html" />
    <link rel="next" title="License" href="license.html" />
    <link rel="prev" title="Matrix Transformations" href="matrices.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="license.html" title="License"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="matrices.html" title="Matrix Transformations"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">ecopy 0.0.5 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="ordination">
<h1>Ordination<a class="headerlink" href="#ordination" title="Permalink to this headline">¶</a></h1>
<p>Ecopy contains numerous methods for ordination, that is, plotting points in reduced space. Techniques include, but are not limited to, principle components analysis (PCA), correspondence analysis (CA), principle coordinates analysis (PCoA), and multidimensional scaling (nMDS).</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference internal" href="#pca" title="pca"><tt class="xref py py-class docutils literal"><span class="pre">pca</span></tt></a> (Principle Components Analysis)</li>
<li><a class="reference internal" href="#ca" title="ca"><tt class="xref py py-class docutils literal"><span class="pre">ca</span></tt></a> (Correspondance Analysis)</li>
<li><a class="reference internal" href="#pcoa" title="pcoa"><tt class="xref py py-class docutils literal"><span class="pre">pcoa</span></tt></a> (Principle Coordinates Analysis)</li>
</ul>
</div></blockquote>
<dl class="class">
<dt id="pca">
<em class="property">class </em><tt class="descname">pca</tt><big>(</big><em>x</em>, <em>scale=True</em>, <em>varNames=None</em><big>)</big><a class="headerlink" href="#pca" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes an input matrix and performs principle components analysis. It will accept either pandas.DataFrames or numpy.ndarrays.  It returns on object of class &#8216;pca&#8217;, with several methods and attributes. This function uses eigenanalysis of covariance matrices rather than SVD decomposition. NOTE: PCA will NOT work with missing observations, as it is up to the user to decide how best to deal with those. Returns object of class <a class="reference internal" href="#pca" title="pca"><tt class="xref py py-class docutils literal"><span class="pre">pca</span></tt></a>.</p>
<p><strong>Parameters</strong></p>
<dl class="docutils">
<dt>x: a numpy.ndarray or pandas.DataFrame</dt>
<dd>A matrix for ordination, where objects are rows and descriptors/variables as columns. Can be either a pandas.DataFrame or numpy. ndarray</dd>
<dt>scale: [True | False]</dt>
<dd>Whether or not the columns should be standardized prior to PCA. If &#8216;True&#8217;, the PCA then operates on a correlation matrix, which is appropriate if variables are on different measurement scales. If variables are on the same scale, use &#8216;False&#8217; to have PCA operate on the covariance matrix.</dd>
<dt>varNames: list</dt>
<dd>If using a numpy.ndarray, pass a list of column names for to help make PCA output easier to interpret. Column names should be in order of the columns in the matrix. Otherwise, column names are represented as integers during summary.</dd>
</dl>
<p><strong>Attributes</strong></p>
<dl class="attribute">
<dt id="pca.evals">
<tt class="descname">evals</tt><a class="headerlink" href="#pca.evals" title="Permalink to this definition">¶</a></dt>
<dd><p>Eigenvalues in order of largest to smallest</p>
</dd></dl>

<dl class="attribute">
<dt id="pca.evecs">
<tt class="descname">evecs</tt><a class="headerlink" href="#pca.evecs" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalized eigenvectors corresponding to each eigenvalue (i.e. the principle axes)</p>
</dd></dl>

<dl class="attribute">
<dt id="pca.scores">
<tt class="descname">scores</tt><a class="headerlink" href="#pca.scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Principle component scores of each object (row) on each principle axis. This returns the raw scores <img class="math" src="_images/math/a01b1c51e370cb2f12af2152cd3c9d61e9fec928.png" alt="\mathbf{F}"/> calculated as <img class="math" src="_images/math/c79cc93d909f71aa88d4abf2aefb3061507a2d18.png" alt="\mathbf{F} = \mathbf{YU}"/> where <img class="math" src="_images/math/c9eadbff3f359c41e6ac5b6bd382a29bb0415c4f.png" alt="\mathbf{U}"/> is the matrix of eigenvectors and <img class="math" src="_images/math/669fb203c2329b8b404de01e7a228bd7c8ca1461.png" alt="\mathbf{Y}"/> are the original observations.</p>
</dd></dl>

<p><strong>Methods</strong></p>
<dl class="classmethod">
<dt id="pca.summary_imp">
<em class="property">classmethod </em><tt class="descname">summary_imp</tt><big>(</big><big>)</big><a class="headerlink" href="#pca.summary_imp" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a data frame containing information about the principle axes.</p>
</dd></dl>

<dl class="classmethod">
<dt id="pca.summary_rot">
<em class="property">classmethod </em><tt class="descname">summary_rot</tt><big>(</big><big>)</big><a class="headerlink" href="#pca.summary_rot" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a data frame containing information on axes rotations (i.e. the eigenvectors).</p>
</dd></dl>

<dl class="classmethod">
<dt id="pca.summary_corr">
<em class="property">classmethod </em><tt class="descname">summary_corr</tt><big>(</big><big>)</big><a class="headerlink" href="#pca.summary_corr" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a data frame containing the correlation of each variable (column) with each principle axis. For example, the correlation of variable <em>i</em> with axis <em>k</em> is calculated as <img class="math" src="_images/math/b4fbc001fe1faedca4fbe93ec14fcaf19c900dcc.png" alt="r_{ik} = u_{ik} \sqrt{\lambda_k} / \sqrt{s_i^2}"/> where <img class="math" src="_images/math/7a72e41c1b2934c12e2340be76876e9d09a1e5b4.png" alt="\lambda_k"/> is the eigenvalue (i.e. variance) associated with axis <em>k</em> and <img class="math" src="_images/math/cb857581c6b7ed6181a37ff77c23fbbd93389521.png" alt="s_i^2"/> is the variance of variable <em>i</em>.</p>
</dd></dl>

<dl class="classmethod">
<dt id="pca.summary_desc">
<em class="property">classmethod </em><tt class="descname">summary_desc</tt><big>(</big><big>)</big><a class="headerlink" href="#pca.summary_desc" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a data frame containing the cumulative variance explained for each predictor along each principle axis</p>
</dd></dl>

<dl class="classmethod">
<dt id="pca.biplot">
<em class="property">classmethod </em><tt class="descname">biplot</tt><big>(</big><em>xax=1</em>, <em>yax=2</em>, <em>type='distance'</em>, <em>obsNames=False</em><big>)</big><a class="headerlink" href="#pca.biplot" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a biplot using a specified transformation.</p>
<dl class="docutils">
<dt>xax: integer</dt>
<dd>Specifies which PC axis to plot on the x-axis</dd>
<dt>yax: integer</dt>
<dd>Specifies which PC axis to plot on the y-axis</dd>
<dt>type: [&#8216;distance&#8217; | &#8216;correlation&#8217;]</dt>
<dd><p class="first">Type &#8216;distance&#8217; plots the raw scores <img class="math" src="_images/math/a01b1c51e370cb2f12af2152cd3c9d61e9fec928.png" alt="\mathbf{F}"/> and the raw vectors <img class="math" src="_images/math/c9eadbff3f359c41e6ac5b6bd382a29bb0415c4f.png" alt="\mathbf{U}"/> of the first two principle axes.</p>
<p class="last">Type &#8216;correlation&#8217; plots scores and vectors scaled by the eigenvalues corresponding to each axis: <img class="math" src="_images/math/44a66cfe07579ce7d67b76edee8ec03e66619414.png" alt="\mathbf{F\Lambda}^{-0.5}"/> and <img class="math" src="_images/math/e600f19c3a15f3106cd0c67597991ce227af8759.png" alt="\mathbf{U\Lambda}^{0.5}"/>, where <img class="math" src="_images/math/e3c83ee2789162e0cccd010dd3f482f78cb4c535.png" alt="\mathbf{\Lambda}"/> is a diagonal matrix containing the eigenvalues.</p>
</dd>
<dt>obsNames: [True | False]</dt>
<dd>Denotes whether to plot a scatterplot of points (False) or to actually show the names of the observations, as taken from the DataFrame index (True).</dd>
</dl>
</dd></dl>

<p><strong>Examples</strong></p>
<p>Principle components analysis of the USArrests data. First, load the data from R using pandas:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">ecopy</span> <span class="kn">as</span> <span class="nn">ep</span>
<span class="kn">import</span> <span class="nn">pandas.rpy.common</span> <span class="kn">as</span> <span class="nn">com</span>
<span class="n">USArrests</span> <span class="o">=</span> <span class="n">com</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s">&#39;USArrests&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, run the PCA:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">arrests_PCA</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">pca</span><span class="p">(</span><span class="n">USArrests</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Check the importance of the different axes by examining the standard deviations, which are the square root of the eigenvalues, and the proportions of variance explained by each axis:</p>
<div class="highlight-python"><pre>impPC = arrests_PCA.summary_imp()
print impPC
            PC1     PC2       PC3     PC4
Std Dev 1.574878 0.994869 0.597129 0.416449
Proportion 0.620060 0.247441 0.089141 0.043358
Cum Prop 0.620060 0.867502 0.956642 1.000000</pre>
</div>
<p>Next, examine the eigenvectors and loadings to determine which variables contribute to which axes:</p>
<div class="highlight-python"><pre>rotPC = arrests_PCA.summary_rot()
print rotPC
         PC1       PC2     PC3        PC4
Murder 0.535899 0.418181 -0.341233 0.649228
Assault 0.583184 0.187986 -0.268148 -0.743407
UrbanPop 0.278191 -0.872806 -0.378016 0.133878
Rape 0.543432 -0.167319 0.817778 0.089024</pre>
</div>
<p>Although the loadings are informative, showing the correlations of each variable with each axis might ease interpretation:</p>
<div class="highlight-python"><pre>print arrests_PCA.summary_corr()
           PC1      PC2      PC3     PC4
Murder 0.843976 0.658584 -0.537400 1.022455
Assault 0.580192 0.187021 -0.266773 -0.739593
UrbanPop 0.166116 -0.521178 -0.225724 0.079942
Rape 0.226312 -0.069680 0.340563 0.037074</pre>
</div>
<p>Then, look to see how much of the variance among predictors is explained by the first two axes:</p>
<div class="highlight-python"><pre>print arrests_PCA.summary_desc()
           PC1      PC2     PC3  PC4
Murder 0.712296 0.885382 0.926900 1
Assault 0.843538 0.878515 0.904153 1
Urban Pop 0.191946 0.945940 0.996892 1
Rape 0.732461 0.760170 0.998626 1</pre>
</div>
<p>Show the biplot using the &#8216;correlation&#8217; scaling. Instead of just a scatterplot, use obsNames=True to show the actual names of observations:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">arrests_PCA</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">&#39;correlation&#39;</span><span class="p">,</span> <span class="n">obsNames</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="_images/corrpca.png" src="_images/corrpca.png" />
</div>
</dd></dl>

<dl class="class">
<dt id="ca">
<em class="property">class </em><tt class="descname">ca</tt><big>(</big><em>x</em>, <em>siteNames=None</em>, <em>spNames=None</em><big>)</big><a class="headerlink" href="#ca" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes an input matrix and performs principle simple correspondence analysis. It will accept either pandas.DataFrames or numpy.ndarrays. Data MUST be 0&#8217;s or positive numbers. <strong>NOTE:</strong> Will NOT work with missing observations, as it is up to the user to decide how best to deal with those. Returns on object of class <a class="reference internal" href="#ca" title="ca"><tt class="xref py py-class docutils literal"><span class="pre">ca</span></tt></a>.</p>
<p><strong>Parameters</strong></p>
<dl class="docutils">
<dt>x: a numpy.ndarray or pandas.DataFrame</dt>
<dd><p class="first">A matrix for ordination, where objects are rows and descriptors/variables as columns. Can be either a pandas.DataFrame or numpy.ndarray. <strong>NOTE:</strong> If the matrix has more variables (columns) than objects (rows), the matrix will be transposed prior to analysis, which reverses the meanings of the matrices as noted.</p>
<p>The matrix is first scaled to proportions by dividing each element by the matrix sum, <img class="math" src="_images/math/6064d092655f8c7f5d0933af8266d03a741e9a29.png" alt="p_{ik} = y_{ik} / \sum_1^i \sum_1^k"/>. Row (site) weights <img class="math" src="_images/math/535b2bfbb0a587e261a0d0af9b7b53e42629b14d.png" alt="w_i"/> are calculated as the sums of row probabilities and column (species) weights <img class="math" src="_images/math/57a4f4616d39cde10b899b1e6369a1ca22e34e79.png" alt="w_k"/> are the sum of column probabilities. NOTE: If <img class="math" src="_images/math/14555ceddb79c166bda85ed43806250d8695cc3f.png" alt="r &lt; c"/> in the original matrix, then row weights give species weights and column weights give site weights due to transposition.</p>
<p>A matrix of chi-squared deviations is then calculated as:</p>
<div class="math">
<p><img src="_images/math/351c1ee24fed1b6d09591a257570bed38be25d9e.png" alt="\mathbf{Q} = \frac{p_{ik} - w_i w_k}{\sqrt{w_i w_k}}"/></p>
</div><p>This is then converted into a sum-of-squared deviations as</p>
<div class="math">
<p><img src="_images/math/576db2860782ae60aef53e57328cbfb439d1c521.png" alt="\mathbf{QQ} = \mathbf{Q'Q}"/></p>
</div><p class="last">Eigen-decomposition of <img class="math" src="_images/math/f3306a27b229b096e4c7371aa14675eeb49a8ba4.png" alt="\mathbf{QQ}"/> yields a diagonal matrix of eigenvalues <img class="math" src="_images/math/e3c83ee2789162e0cccd010dd3f482f78cb4c535.png" alt="\mathbf{\Lambda}"/> and a matrix of eigenvectors <img class="math" src="_images/math/c9eadbff3f359c41e6ac5b6bd382a29bb0415c4f.png" alt="\mathbf{U}"/>. Left-hand eigenvectors <img class="math" src="_images/math/a9af02f8312576eff64b05a7479bfcd320e07a76.png" alt="\mathbf{\hat{U}}"/> (as determined by SVD) are calculated as  <img class="math" src="_images/math/56673805cbc27d5d69df14289f5f2fbf4837e72c.png" alt="\mathbf{\hat{U}} = \mathbf{QU\Lambda}^{-0.5}"/>. <img class="math" src="_images/math/c9eadbff3f359c41e6ac5b6bd382a29bb0415c4f.png" alt="\mathbf{U}"/> gives the column (species) loadings and <img class="math" src="_images/math/a9af02f8312576eff64b05a7479bfcd320e07a76.png" alt="\mathbf{\hat{U}}"/> gives the row (site) loadings. NOTE: If <img class="math" src="_images/math/14555ceddb79c166bda85ed43806250d8695cc3f.png" alt="r &lt; c"/> in the original matrix, the roles of these matrices are reversed.</p>
</dd>
<dt>siteNames: list</dt>
<dd>A list of site names. If left blank, site names are taken as the index of the pandas.DataFrame or the row index from the numpy.ndarray.</dd>
<dt>spNames: list</dt>
<dd>A list of species names. If left blank, species names are taken as the column names of the pandas.DataFrame or the column index from the numpy.ndarray.</dd>
</dl>
<p><strong>Attributes</strong></p>
<dl class="attribute">
<dt id="ca.w_col">
<tt class="descname">w_col</tt><a class="headerlink" href="#ca.w_col" title="Permalink to this definition">¶</a></dt>
<dd><p>Column weights in the proportion matrix. Normally species weights unless <img class="math" src="_images/math/2d022082951bb4cc397d7d79a930c931fb07af10.png" alt="r&lt;c"/>, in which case they are site weights.</p>
</dd></dl>

<dl class="attribute">
<dt id="ca.w_row">
<tt class="descname">w_row</tt><a class="headerlink" href="#ca.w_row" title="Permalink to this definition">¶</a></dt>
<dd><p>Row weights in the proportion matrix. Normally site weights unless <img class="math" src="_images/math/2d022082951bb4cc397d7d79a930c931fb07af10.png" alt="r&lt;c"/>, in which case they are species weights.</p>
</dd></dl>

<dl class="attribute">
<dt id="ca.U">
<tt class="descname">U</tt><a class="headerlink" href="#ca.U" title="Permalink to this definition">¶</a></dt>
<dd><p>Column (species) eigenvectors (see above note on transposition)</p>
</dd></dl>

<dl class="attribute">
<dt id="ca.Uhat">
<tt class="descname">Uhat</tt><a class="headerlink" href="#ca.Uhat" title="Permalink to this definition">¶</a></dt>
<dd><p>Row (site) eigenvectors (see above note on transposition)</p>
</dd></dl>

<dl class="attribute">
<dt id="ca.cumDesc_Sp">
<tt class="descname">cumDesc_Sp</tt><a class="headerlink" href="#ca.cumDesc_Sp" title="Permalink to this definition">¶</a></dt>
<dd><p>pandas.DataFrame of the cumulative contribution of each eigenvector to each species. Matrix <img class="math" src="_images/math/c9eadbff3f359c41e6ac5b6bd382a29bb0415c4f.png" alt="\mathbf{U}"/> is scaled by eigenvalues <img class="math" src="_images/math/769931d512182d99c50923aafa7f9e39f0488898.png" alt="\mathbf{U_2} = \mathbf{U\Lambda}^{0.5}"/>. Then, the cumulative sum of each column is divided by the column total for every row. If <img class="math" src="_images/math/14555ceddb79c166bda85ed43806250d8695cc3f.png" alt="r &lt; c"/> in the original data, then this operation is performed on <img class="math" src="_images/math/a9af02f8312576eff64b05a7479bfcd320e07a76.png" alt="\mathbf{\hat{U}}"/> automatically.</p>
</dd></dl>

<p><strong>Methods</strong></p>
<dl class="classmethod">
<dt id="ca.summary">
<em class="property">classmethod </em><tt class="descname">summary</tt><big>(</big><big>)</big><a class="headerlink" href="#ca.summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a pandas.DataFrame of summary information for each correspondence axis, including SD&#8217;s (square-root of each eigenvalue), proportion of inertia explained, and cumulative inertia explained.</p>
</dd></dl>

<dl class="classmethod">
<dt id="ca.biplot">
<em class="property">classmethod </em><tt class="descname">biplot</tt><big>(</big><em>coords=False</em>, <em>type=1</em>, <em>xax=1</em>, <em>yax=2</em>, <em>showSp=True</em>, <em>showSite=True</em>, <em>spCol='r'</em>, <em>siteCol='k'</em>, <em>spSize=12</em>, <em>siteSize=12</em>, <em>xlim=None</em>, <em>ylim=None</em><big>)</big><a class="headerlink" href="#ca.biplot" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a biplot of the given CA axes.</p>
<dl class="docutils">
<dt>coords: [True | False]</dt>
<dd>If True, returns a dictionary of plotted coordinates. Type 1 plots can be reproduced using F and V, Type 2 plots can be reproduced using Fhat and Vhat (see below). Note: This only returns the axes specified by xax and yax (see below).</dd>
<dt>xax: integer</dt>
<dd>Specifies CA axis to plot on the x-axis</dd>
<dt>yax: integer</dt>
<dd>Specifies CA axis to plot on the y-axis (Default=2)</dd>
<dt>showSp: [True | False]</dt>
<dd>Whether or not to show species in the plot</dd>
<dt>showSite: [True | False]</dt>
<dd>Whether or not to show sites in the plot</dd>
<dt>spCol: string</dt>
<dd>Color of species text</dd>
<dt>siteCol: string</dt>
<dd>Color of site text</dd>
<dt>spSize: integer</dt>
<dd>Size of species text</dd>
<dt>siteSize: integer</dt>
<dd>Size of site text</dd>
<dt>xlim: list</dt>
<dd>A list of x-axis limits to override default</dd>
<dt>ylim: list</dt>
<dd>A list of y-axis limits to override default</dd>
<dt>type: [1 | 2]</dt>
<dd><p class="first">Which type of biplot to produce. 1 produces a site biplot, 2 produces a species biplot. In biplots, only the first two axes are shown. The plots are constructed as follows:</p>
<p>Four matrices are constructed. Outer species (column) locations on CA axes <img class="math" src="_images/math/9d5b9321f67eecfa2013fa6f3891ba1f2e335946.png" alt="\mathbf{V}"/> are given by the species (column) weights multiplied by the species (column) eigenvalues:</p>
<div class="math">
<p><img src="_images/math/40bde3dfe732255a10797d6a23c6e692ca34ef55.png" alt="\mathbf{V} = \mathbf{D_k}^{-0.5}\mathbf{U}"/></p>
</div><p>where <img class="math" src="_images/math/304d6317211eefb68f1c69535cc6594f7242111b.png" alt="\mathbf{D_k}"/> is a diagonal matrix of species (column) weights <cite>w_k</cite>.  Likewise, outer site (row) locations are given by:</p>
<div class="math">
<p><img src="_images/math/fd72ea3cfb53eec81597155487fcc4a5f03d0026.png" alt="\mathbf{\hat{V}} = \mathbf{D_i}^{-0.5}\mathbf{\hat{U}}"/></p>
</div><p>Inner site locations <img class="math" src="_images/math/a01b1c51e370cb2f12af2152cd3c9d61e9fec928.png" alt="\mathbf{F}"/> are given as:</p>
<div class="math">
<p><img src="_images/math/ce9b8e635339bd3394e2fd31e7a7721e1d7dd382.png" alt="\mathbf{F} = \mathbf{\hat{V}}\mathbf{\Lambda^{0.5}}"/></p>
</div><p>Inner species locations are given as:</p>
<div class="math">
<p><img src="_images/math/d07ae72f0b646d2fe70b4627f92c9ec35b4058c7.png" alt="\mathbf{\hat{F}} = \mathbf{V}\mathbf{\Lambda^{0.5}}"/></p>
</div><p>Type 1 Biplot: Type 1 shows the relationships among sites within the centroids of the species. This plot is useful for examining relationships among sites and how sites are composed of species. In this, the first two columns of inner site locations <img class="math" src="_images/math/a01b1c51e370cb2f12af2152cd3c9d61e9fec928.png" alt="\mathbf{F}"/> are plotted against the first two columns of the outer species locations <img class="math" src="_images/math/9d5b9321f67eecfa2013fa6f3891ba1f2e335946.png" alt="\mathbf{V}"/>. NOTE: If <img class="math" src="_images/math/14555ceddb79c166bda85ed43806250d8695cc3f.png" alt="r &lt; c"/> in the original matrix, this will be <img class="math" src="_images/math/7db7f812bd594ded792fe1396d363f8aff65c087.png" alt="\mathbf{\hat{F}}"/> and <img class="math" src="_images/math/530822ae6a52e8826fe6aedff7102c392975d2c4.png" alt="\mathbf{\hat{V}}"/>.</p>
<p>Type 2 Biplot: Type 2 shows the relationships among species within the centroids of the sites. This plot is useful for examining relationships among species and how species are distributed among sites. In this, the first two columns of inner species locations <img class="math" src="_images/math/7db7f812bd594ded792fe1396d363f8aff65c087.png" alt="\mathbf{\hat{F}}"/>  are plotted against the first two columns of the outer site locations <img class="math" src="_images/math/530822ae6a52e8826fe6aedff7102c392975d2c4.png" alt="\mathbf{\hat{V}}"/>. NOTE: If <img class="math" src="_images/math/14555ceddb79c166bda85ed43806250d8695cc3f.png" alt="r &lt; c"/> in the original matrix, this will be <img class="math" src="_images/math/a01b1c51e370cb2f12af2152cd3c9d61e9fec928.png" alt="\mathbf{F}"/> and <img class="math" src="_images/math/9d5b9321f67eecfa2013fa6f3891ba1f2e335946.png" alt="\mathbf{V}"/>.</p>
<dl class="last docutils">
<dt>coords: [True | False]</dt>
<dd>If True, then return a dictionary of the <img class="math" src="_images/math/a01b1c51e370cb2f12af2152cd3c9d61e9fec928.png" alt="\mathbf{F}"/>, <img class="math" src="_images/math/7db7f812bd594ded792fe1396d363f8aff65c087.png" alt="\mathbf{\hat{F}}"/>, <img class="math" src="_images/math/9d5b9321f67eecfa2013fa6f3891ba1f2e335946.png" alt="\mathbf{V}"/>, and <img class="math" src="_images/math/530822ae6a52e8826fe6aedff7102c392975d2c4.png" alt="\mathbf{\hat{V}}"/> matrices so the user can customize plots. See above for description of these matrices. Dictionary keys are &#8216;F&#8217;, &#8216;Fhat&#8217;, &#8216;V&#8217;, and &#8216;Vhat&#8217;. NOTE: Any adjustments for matrix transposition have already taken place, so &#8216;F&#8217; gives site inner coordinates, &#8216;V&#8217; gives species outer coordinates, &#8216;Fhat&#8217; gives species inner coordinates, and &#8216;Vhat&#8217; gives site outer coordinates regardless of matrix shape. Type 1 plot can always be reproduced using &#8216;F&#8217; (sites) and &#8216;V&#8217; (species) and Type 2 plot can always be reproduced using &#8216;Fhat&#8217; (species) and &#8216;Vhat&#8217; (sites).</dd>
</dl>
</dd>
</dl>
</dd></dl>

<p><strong>Examples</strong></p>
<p>In Legendre and Legendre (2012), there is an example of three species varying among three lakes. Write in that data:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">ecopy</span> <span class="kn">as</span> <span class="nn">ep</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">Lakes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="n">Lakes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">Lakes</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;L1&#39;</span><span class="p">,</span> <span class="s">&#39;L2&#39;</span><span class="p">,</span> <span class="s">&#39;L3&#39;</span><span class="p">])</span>
<span class="n">Lakes</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;Sp1&#39;</span><span class="p">,</span> <span class="s">&#39;Sp2&#39;</span><span class="p">,</span> <span class="s">&#39;Sp3&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Next, run the CA:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">lakes_CA</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">ca</span><span class="p">(</span><span class="n">Lakes</span><span class="p">)</span>
</pre></div>
</div>
<p>Check the variance explained by each CA axis (there will only be two):</p>
<div class="highlight-python"><pre>CA_summary = lakes_CA.summary()
print CA_summary
          CA Axis 1 CA Axis 2
Std. Dev 0.310053 0.202341
Prop. 0.701318 0.298682
Cum. Prop. 0.701318 1.000000</pre>
</div>
<p>Next, see how well the two axes explained variance in species and sites:</p>
<div class="highlight-python"><pre>rotPC = arrests_PCA.summary_rot()
print rotPC
         PC1       PC2     PC3        PC4
Murder 0.535899 0.418181 -0.341233 0.649228
Assault 0.583184 0.187986 -0.268148 -0.743407
UrbanPop 0.278191 -0.872806 -0.378016 0.133878
Rape 0.543432 -0.167319 0.817778 0.089024</pre>
</div>
<p>Although the loadings are informative, showing the correlations of each variable with each axis might ease interpretation:</p>
<div class="highlight-python"><pre>print lakes_CA.cumDesc_Sp
   CA Axis 1 CA Axis 2
Sp1 0.971877 1
Sp2 0.129043 1
Sp3 0.732340 1

print lakes_CA.cumDesc_site
    CA Axis 1 CA Axis 2
L1 0.684705 1
L2 0.059355 1
L3 0.967209 1</pre>
</div>
<p>Make a Type 1 biplot to look at the relationship among sites:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">lakes_CA</span><span class="o">.</span><span class="n">biplot</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="_images/ca_1.png" src="_images/ca_1.png" />
</div>
<p>In a bigger example, run CA on the BCI dataset. <strong>NOTE: This is an example where</strong> <img class="math" src="_images/math/14555ceddb79c166bda85ed43806250d8695cc3f.png" alt="r &lt; c"/>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">pandas.rpy.common</span> <span class="kn">as</span> <span class="nn">com</span>
<span class="n">BCI</span> <span class="o">=</span> <span class="n">com</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="s">&#39;BCI&#39;</span><span class="p">,</span> <span class="s">&#39;vegan&#39;</span><span class="p">)</span>
<span class="n">bci_ca</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">ca</span><span class="p">(</span><span class="n">BCI</span><span class="p">)</span>
<span class="n">bci_ca</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">showSp</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="_images/ca3.png" src="_images/ca3.png" />
</div>
</dd></dl>

<dl class="class">
<dt id="pcoa">
<em class="property">class </em><tt class="descname">pcoa</tt><big>(</big><em>x</em>, <em>correction=None</em>, <em>siteNames=None</em><big>)</big><a class="headerlink" href="#pcoa" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a square-symmetric distance matrix with no negative values as input. <strong>NOTE:</strong> This will not work with missing observations. Returns an object of class <a class="reference internal" href="#pcoa" title="pcoa"><tt class="xref py py-class docutils literal"><span class="pre">pcoa</span></tt></a>.</p>
<p><strong>Parameters</strong></p>
<dl class="docutils">
<dt>x: a numpy.ndarray or pandas.DataFrame</dt>
<dd><p class="first">A square, symmetric distance matrix with no negative values and no missing observations. Diagonal entries should be 0.</p>
<p class="last">For PCoA, distance matrix <img class="math" src="_images/math/5f61118f2ae912f86e683687c005145b5eb54aec.png" alt="\mathbf{x}"/> is first corrected to a new matrix <img class="math" src="_images/math/f3e830722dede854af533bfa96d549c68ed5997f.png" alt="\mathbf{A}"/>, where <img class="math" src="_images/math/1a37289cb23474d28df3bf14ef9b8ce14bcd5a87.png" alt="a_{ij} = -0.5*x_{ij}^2"/>. Elements of the new matrix <img class="math" src="_images/math/f3e830722dede854af533bfa96d549c68ed5997f.png" alt="\mathbf{A}"/> are centered by row and column means using the equation <img class="math" src="_images/math/285a942494a501338e87062021745028e5b875ca.png" alt="\mathbf{\Delta_1} = \mathbf{(I - \frac{1'1}{n})A(I - \frac{1'1}{n})}"/>. PCoA is eigenanalysis of <img class="math" src="_images/math/84e114a222cafeefb0026c1cfb0cfb405f9a3fce.png" alt="\mathbf{\Delta_1}"/>. Eigenvectors <img class="math" src="_images/math/c9eadbff3f359c41e6ac5b6bd382a29bb0415c4f.png" alt="\mathbf{U}"/> are scaled by the square root of each eigenvalue <img class="math" src="_images/math/73e427852c98fb6ce863c8dbeaf20f0448267a59.png" alt="\mathbf{U_{scl}} = \mathbf{U}\mathbf{\Lambda^{0.5}}"/> where <img class="math" src="_images/math/e3c83ee2789162e0cccd010dd3f482f78cb4c535.png" alt="\mathbf{\Lambda}"/> is a diagonal matrix of the eigenvalues.</p>
</dd>
<dt>correction: [None | 1 | 2]</dt>
<dd><p class="first">Which correction should be applied for negative eigenvalues. Accepts either &#8216;1&#8217; or &#8216;2&#8217; (must be a string). By default, no correction is applied.</p>
<p><em>Correction 1</em>: Computes PCoA as described above. Adds the absolute value of the largest negative eigenvalue to the square original distance matrix (while keeping diagonals as 0) and then re-runs PCoA from the beginning.</p>
<p><em>Correction 2</em>: Constructs a special matrix</p>
<div class="math">
<p><img src="_images/math/5c53e09e956f9f22903bec5855c7cf3d97f9883a.png" alt="\begin{bmatrix} \mathbf{0} &amp; 2\mathbf{\Delta_1} \\ -\mathbf{I} &amp; -4\mathbf{\Delta_2} \end{bmatrix}"/></p>
</div><p class="last"><img class="math" src="_images/math/b775759b9856a36d4215166128950d35a26ff892.png" alt="\Delta_1"/> is the centered, corrected distance matrix as described above and <img class="math" src="_images/math/8b8338250c7835a01448391b413fdb03939b9d74.png" alt="\Delta_2"/> is a centered matrix (uncorrected) of <img class="math" src="_images/math/8a0990c859c315621d8ba5de872b0b69d2e8a4f8.png" alt="-0.5\mathbf{x}"/>. The largest, positive eigenvalue of this matrix is then added the original distances and PCoA run from the beginning.</p>
</dd>
<dt>siteNames: list</dt>
<dd>A list of site names. If not passed, inherits from the DataFrame index or assigns integer values.</dd>
</dl>
<p><strong>Attributes</strong></p>
<dl class="attribute">
<dt id="pcoa.evals">
<tt class="descname">evals</tt><a class="headerlink" href="#pcoa.evals" title="Permalink to this definition">¶</a></dt>
<dd><p>Eigenvalues of each principle coordinate axis</p>
</dd></dl>

<dl class="attribute">
<dt id="pcoa.U">
<tt class="descname">U</tt><a class="headerlink" href="#pcoa.U" title="Permalink to this definition">¶</a></dt>
<dd><p>Eignevectors describing each axis. These have already been scaled.</p>
</dd></dl>

<dl class="attribute">
<dt id="pcoa.correction">
<tt class="descname">correction</tt><a class="headerlink" href="#pcoa.correction" title="Permalink to this definition">¶</a></dt>
<dd><p>The correction factor applied to correct for negative eignvalues.</p>
</dd></dl>

<p><strong>Methods</strong></p>
<dl class="classmethod">
<dt id="pcoa.summary">
<em class="property">classmethod </em><tt class="descname">summary</tt><big>(</big><big>)</big><a class="headerlink" href="#pcoa.summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a pandas.DataFrame summarizing the variance explained by each principle coordinate axis.</p>
</dd></dl>

<dl class="classmethod">
<dt>
<tt class="descname">biplot(coords=False, xax=1, yax=2, descriptors=None, descripNames=None, spCol='r', siteCol='k', spSize=12, siteSize=12):</tt></dt>
<dd><p>Produces a biplot of the given PCoA axes.</p>
<dl class="docutils">
<dt>coords: [True | False]</dt>
<dd>If True, returns a dictionary of the plotted axes, where &#8216;Objects&#8217; gives the coordinates of objects and &#8216;Descriptors&#8217; gives the coordinates of the descriptors, if any.</dd>
<dt>xax: integer</dt>
<dd>Specifies CA axis to plot on the x-axis</dd>
<dt>yax: integer</dt>
<dd>Specifies CA axis to plot on the y-axis (Default=2)</dd>
<dt>descriptors:  numpy.ndarray or pandas.DataFrame</dt>
<dd><p class="first">An n x m matrix of descriptors to plot on the biplot. These can be the original descriptors used to calculate distances among objects or an entirely new set. Descriptors must be quantitative. It will work for binary descriptors, but may be meaningless.</p>
<p>Given a new matrix $latex mathbf{Y}$ of descriptors, the matrix is standardized by columns to produce a new matrix $latex mathbf{Y_{scl}}$. The given principle coordinate axes denoted by xax and yax are placed into an n x 2 matrix $latex mathbf{V}$, which is also standardized by column. The covariance between the new descriptors and principle coordinates is given by</p>
<div class="math">
<p><img src="_images/math/681b89f9020ea4d6acbdab746327bf6cb9697446.png" alt="\mathbf{S} = \frac{1}{n-1}\mathbf{Y'_{scl}V}"/></p>
</div><p>The covariance $latex mathbf{S}$ is then scaled by the eigenvalues corresponding to the given eigenvectors:</p>
<div class="math">
<p><img src="_images/math/bb504f96111788f0e8eebf76a5c1c29bb9acd221.png" alt="\mathbf{Y_{proj}} = \sqrt{n-1}\mathbf{S\Lambda^{-0.5}}"/></p>
</div><p class="last">Matrix $latex Y_{proj}$ contains the coordinates of each descriptor and is what is returns as &#8216;Descriptors&#8217; if coords=True.</p>
</dd>
<dt>descripNames: list</dt>
<dd>A list containing the names of each descriptor. If None, inherits from the column names of the pandas.DataFrame or assigned integer values.</dd>
<dt>spCol: string</dt>
<dd>Color of species text</dd>
<dt>siteCol: string</dt>
<dd>Color of site text</dd>
<dt>spSize: integer</dt>
<dd>Size of species text</dd>
<dt>siteSize: integer</dt>
<dd>Size of site text</dd>
</dl>
</dd></dl>

<dl class="classmethod">
<dt>
<tt class="descname">shepard(xax=1, yax=2):</tt></dt>
<dt>
<tt class="descname">Plots a Shepard diagram of Euclidean distances among objects in reduced space vs. original distance calculations. xax and yax as above.</tt></dt>
<dd></dd></dl>

<p><strong>Examples</strong></p>
<p>Run PCoA on the &#8216;BCI&#8217; data:</p>
<div class="highlight-python"><pre>import pandas.rpy.common as com
import ecopy as ep

BCI = com.load_data('BCI', 'vegan')
brayD = ep.distance(BCI, method='bray', transform='sqrt')
pc1 = ep.pcoa(brayD)
print pc1.summary()[['PCoA Axis 1', 'PCoA Axis 2']]

        PCoA Axis 1 PCoA Axis 2
Std. Dev 1.094943 0.962549
Prop. 0.107487 0.083065
Cum. Prop. 0.107487 0.190552

pc1.biplot()</pre>
</div>
<div class="figure align-center">
<img alt="_images/pcoa1.png" src="_images/pcoa1.png" />
</div>
<p>Attempting to show species on the above biplot results in a messy graph. To better illustrate its use, run PCoA on the USArrests data:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">USA</span> <span class="o">=</span> <span class="n">com</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="s">&#39;USArrests&#39;</span><span class="p">)</span>
<span class="c"># standardize columns first</span>
<span class="n">USA</span> <span class="o">=</span> <span class="n">USA</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">eucD</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">USA</span><span class="p">,</span> <span class="s">&#39;euclidean&#39;</span><span class="p">)</span>

<span class="n">pc2</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">pcoa</span><span class="p">(</span><span class="n">eucD</span><span class="p">,</span> <span class="n">siteNames</span><span class="o">=</span><span class="n">USA</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">pc2</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">descriptors</span><span class="o">=</span><span class="n">USA</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<img alt="_images/pcoa_arrests.png" src="_images/pcoa_arrests.png" />
</div>
</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="matrices.html"
                        title="previous chapter">Matrix Transformations</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="license.html"
                        title="next chapter">License</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/ordination.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="license.html" title="License"
             >next</a> |</li>
        <li class="right" >
          <a href="matrices.html" title="Matrix Transformations"
             >previous</a> |</li>
        <li><a href="index.html">ecopy 0.0.5 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, Nathan Lemoine.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.
    </div>
  </body>
</html>